{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"25141cba48d643adb3dbad1880d5c702":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1807486034c4e9f9c4ed140ca33e4fc","IPY_MODEL_ac27047a741a4aaba1e5e96596430452","IPY_MODEL_e7dc218627c640679febfd74c219123e"],"layout":"IPY_MODEL_c5186f6d47b44eaa873385e871ebbbf8"}},"c1807486034c4e9f9c4ed140ca33e4fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0f2af7d9430454e8b1b2a36d75ff178","placeholder":"​","style":"IPY_MODEL_2916384bc2e44d278c13d0cfddd00b5a","value":"  2%"}},"ac27047a741a4aaba1e5e96596430452":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1acd2e5c2f4038babc5464c5dabf86","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_509b9e58ac384292bc13503ef7a36515","value":1}},"e7dc218627c640679febfd74c219123e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7042627484d4551ab282c6ca08e76ac","placeholder":"​","style":"IPY_MODEL_0605f6f762cd4aeca4131234fb2dd8bd","value":" 1/51 [01:36&lt;1:20:22, 96.45s/it]"}},"c5186f6d47b44eaa873385e871ebbbf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0f2af7d9430454e8b1b2a36d75ff178":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2916384bc2e44d278c13d0cfddd00b5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b1acd2e5c2f4038babc5464c5dabf86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509b9e58ac384292bc13503ef7a36515":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7042627484d4551ab282c6ca08e76ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0605f6f762cd4aeca4131234fb2dd8bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ssqueezepy mne","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIqQiSfRd7BF","outputId":"ce76f101-c5a1-4d23-a67d-88519b5c5a60","execution":{"iopub.status.busy":"2023-01-21T10:11:56.964416Z","iopub.execute_input":"2023-01-21T10:11:56.964761Z","iopub.status.idle":"2023-01-21T10:12:10.293035Z","shell.execute_reply.started":"2023-01-21T10:11:56.964675Z","shell.execute_reply":"2023-01-21T10:12:10.291835Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting ssqueezepy\n  Downloading ssqueezepy-0.6.3-py3-none-any.whl (125 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.0/125.0 kB\u001b[0m \u001b[31m285.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: mne in /opt/conda/lib/python3.7/site-packages (1.3.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from ssqueezepy) (1.7.3)\nRequirement already satisfied: numba in /opt/conda/lib/python3.7/site-packages (from ssqueezepy) (0.55.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ssqueezepy) (1.21.6)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from mne) (3.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from mne) (4.64.0)\nRequirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.7/site-packages (from mne) (1.6.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from mne) (5.1.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mne) (22.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from mne) (3.5.3)\nRequirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.5->mne) (1.4.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from pooch>=1.5->mne) (2.28.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->mne) (2.1.1)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (9.1.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (1.4.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (2.8.2)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (3.0.9)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->mne) (4.33.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba->ssqueezepy) (59.8.0)\nRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba->ssqueezepy) (0.38.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.15.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.13)\nInstalling collected packages: ssqueezepy\nSuccessfully installed ssqueezepy-0.6.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport cv2\nimport os\nimport tqdm.notebook as tq\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport random\nfrom glob import glob\nimport scipy.io\nimport torch.nn as nn\nimport numpy as np\nimport os\nimport sys\nimport re\nimport pandas as pd\nfrom skimage.transform import resize\nimport warnings\nfrom pathlib import Path \nimport pickle\nimport mne\nfrom ssqueezepy import cwt\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"O5PHp9dJbI0a","execution":{"iopub.status.busy":"2023-01-21T10:12:10.296314Z","iopub.execute_input":"2023-01-21T10:12:10.296701Z","iopub.status.idle":"2023-01-21T10:12:14.661908Z","shell.execute_reply.started":"2023-01-21T10:12:10.296670Z","shell.execute_reply":"2023-01-21T10:12:14.660949Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!mkdir ~/.kaggle\n!touch ~/.kaggle/kaggle.json\napi_token = {\"username\":\"****\",\"key\":\"****\"}\nimport json\n\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n\n!chmod 600 ~/.kaggle/kaggle.json\n!kaggle competitions download -c alvi-hack-2023\n!unzip alvi-hack-2023.zip ","metadata":{"id":"oX_IzuwbdFhk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a059d3bd-1b2f-45d7-a763-767b212ef556","execution":{"iopub.status.busy":"2023-01-21T10:12:14.663160Z","iopub.execute_input":"2023-01-21T10:12:14.663725Z","iopub.status.idle":"2023-01-21T10:12:38.413753Z","shell.execute_reply.started":"2023-01-21T10:12:14.663688Z","shell.execute_reply":"2023-01-21T10:12:38.412580Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading alvi-hack-2023.zip to /kaggle/working\n100%|███████████████████████████████████████▊| 228M/229M [00:13<00:00, 22.1MB/s]\n100%|████████████████████████████████████████| 229M/229M [00:13<00:00, 17.6MB/s]\nArchive:  alvi-hack-2023.zip\n  inflating: data_submission/00.npz  \n  inflating: data_submission/01.npz  \n  inflating: data_submission/02.npz  \n  inflating: data_submission/03.npz  \n  inflating: data_submission/04.npz  \n  inflating: data_submission/05.npz  \n  inflating: data_submission/06.npz  \n  inflating: data_submission/07.npz  \n  inflating: data_submission/08.npz  \n  inflating: data_submission/09.npz  \n  inflating: data_submission/10.npz  \n  inflating: data_submission/11.npz  \n  inflating: data_submission/12.npz  \n  inflating: data_submission/13.npz  \n  inflating: data_submission/14.npz  \n  inflating: data_train/00.npz       \n  inflating: data_train/01.npz       \n  inflating: data_train/02.npz       \n  inflating: data_train/03.npz       \n  inflating: data_train/04.npz       \n  inflating: data_train/05.npz       \n  inflating: data_train/06.npz       \n  inflating: data_train/07.npz       \n  inflating: data_train/08.npz       \n  inflating: data_train/09.npz       \n  inflating: data_train/10.npz       \n  inflating: data_train/11.npz       \n  inflating: data_train/12.npz       \n  inflating: data_train/13.npz       \n  inflating: data_train/14.npz       \n  inflating: data_train/15.npz       \n  inflating: data_train/16.npz       \n  inflating: data_train/17.npz       \n  inflating: data_train/18.npz       \n  inflating: data_train/19.npz       \n  inflating: data_train/20.npz       \n  inflating: data_train/21.npz       \n  inflating: data_train/22.npz       \n  inflating: data_train/23.npz       \n  inflating: data_train/24.npz       \n  inflating: data_train/25.npz       \n  inflating: data_train/26.npz       \n  inflating: data_train/27.npz       \n  inflating: data_train/28.npz       \n  inflating: data_train/29.npz       \n  inflating: data_train/30.npz       \n  inflating: data_train/31.npz       \n  inflating: data_train/32.npz       \n  inflating: data_train/33.npz       \n  inflating: data_train/34.npz       \n  inflating: data_train/35.npz       \n  inflating: data_train/36.npz       \n  inflating: data_train/37.npz       \n  inflating: data_train/38.npz       \n  inflating: data_train/39.npz       \n  inflating: data_train/40.npz       \n  inflating: data_train/41.npz       \n  inflating: data_train/42.npz       \n  inflating: data_train/43.npz       \n  inflating: data_train/44.npz       \n  inflating: data_train/45.npz       \n  inflating: data_train/46.npz       \n  inflating: data_train/47.npz       \n  inflating: data_train/48.npz       \n  inflating: data_train/49.npz       \n  inflating: data_train/50.npz       \n  inflating: data_train/51.npz       \n  inflating: data_train/52.npz       \n  inflating: data_train/53.npz       \n  inflating: data_train/54.npz       \n  inflating: data_train/55.npz       \n  inflating: data_train/56.npz       \n  inflating: data_train/57.npz       \n","output_type":"stream"}]},{"cell_type":"code","source":"class GenBlock(nn.Module):\n    def __init__(self, in_features, out_features, stride=2,padding=1, down=True, activation='relu', dropout=False):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_features, out_features, 4, stride, padding, bias=False, padding_mode='reflect') \n            if down else nn.ConvTranspose2d(in_features, out_features, 4, stride, padding, bias=False),\n            nn.BatchNorm2d(out_features),\n            nn.ReLU() if activation == 'relu' else nn.LeakyReLU(0.2)\n        )\n        self.use_dropout = dropout\n        self.dropout = nn.Dropout(0.5)\n    \n    def forward(self, x):\n        x = self.conv(x)\n        return x if not self.use_dropout else self.dropout(x)","metadata":{"id":"xHasGEupiQYj","execution":{"iopub.status.busy":"2023-01-21T10:12:38.416393Z","iopub.execute_input":"2023-01-21T10:12:38.417050Z","iopub.status.idle":"2023-01-21T10:12:38.425755Z","shell.execute_reply.started":"2023-01-21T10:12:38.417010Z","shell.execute_reply":"2023-01-21T10:12:38.424444Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, in_channels=8, features=64):\n        super().__init__()\n        self.down1 = nn.Sequential(\n            nn.Conv2d(in_channels, features, 4, 2, 1, bias=False, padding_mode='reflect'),\n            nn.LeakyReLU(0.2)\n        ) #128\n        \n        self.down2 = GenBlock(features, 2*features, down=True, activation='leaky', dropout=False) #64\n        self.down3 = GenBlock(2*features, 2*features, down=True, activation='leaky', dropout=False) #32\n        self.down4 = GenBlock(2*features, 4*features, down=True, activation='leaky', dropout=False) #16\n        self.down5 = GenBlock(4*features, 4*features,padding=0, down=True, activation='leaky', dropout=False) #8\n        self.down6 = GenBlock(4*features, 8*features, down=True, activation='leaky', dropout=False) #4\n\n        self.bottleneck = nn.Sequential(\n            nn.Conv2d(8*features, 16*features, kernel_size=1, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(16*features, 8*features, kernel_size=1, stride=2, padding=1),\n            nn.ReLU()\n        )\n\n        self.up1 = GenBlock(2*8*features, 4*features, down=False, activation='relu', dropout=True) #8\n        self.up2 = GenBlock(2*4*features, 4*features,padding=0, down=False, activation='relu', dropout=True) #16\n        self.up3 = GenBlock(2*4*features, 2*features, down=False, activation='relu', dropout=True) #32\n        self.up4 = GenBlock(2*2*features, 2*features, down=False, activation='relu', dropout=True) #64\n        self.up5 = GenBlock(2*2*features, features, down=False, activation='relu', dropout=True) #128\n        self.up6 = nn.Sequential(\n            nn.ConvTranspose2d(2*features, in_channels, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()\n        ) #256\n\n    def forward(self, x):\n        d1 = self.down1(x)\n        d2 = self.down2(d1)\n\n        d3 = self.down3(d2)\n        d4 = self.down4(d3)\n        d5 = self.down5(d4)\n        d6 = self.down6(d5)\n        bn = self.bottleneck(d6)\n        u1 = self.up1(torch.cat([bn, d6], dim=1))\n        u2 = self.up2(torch.cat([u1, d5], dim=1))\n        u3 = self.up3(torch.cat([u2, d4], dim=1))\n        u4 = self.up4(torch.cat([u3, d3], dim=1))\n        u5 = self.up5(torch.cat([u4, d2], dim=1))\n        u6 = self.up6(torch.cat([u5, d1], dim=1))\n        return u6\n","metadata":{"id":"21JAR_pe4VJj","execution":{"iopub.status.busy":"2023-01-21T07:43:52.881404Z","iopub.execute_input":"2023-01-21T07:43:52.881766Z","iopub.status.idle":"2023-01-21T07:43:52.901544Z","shell.execute_reply.started":"2023-01-21T07:43:52.881732Z","shell.execute_reply":"2023-01-21T07:43:52.900605Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=2):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode='reflect'),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2)\n        )\n    def forward(self, x):\n        return self.conv(x)","metadata":{"id":"GupMQ9Udlo5v","execution":{"iopub.status.busy":"2023-01-21T07:43:52.904960Z","iopub.execute_input":"2023-01-21T07:43:52.905237Z","iopub.status.idle":"2023-01-21T07:43:52.914542Z","shell.execute_reply.started":"2023-01-21T07:43:52.905212Z","shell.execute_reply":"2023-01-21T07:43:52.913549Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Descriminator(nn.Module):\n    def __init__(self, in_channels=8):\n        super().__init__()\n        self.initial = nn.Sequential(\n            nn.Conv2d(in_channels, 64, kernel_size=4, stride=2, padding=1, padding_mode='reflect'),\n            nn.LeakyReLU(0.2)\n        )\n        self.model = nn.Sequential(\n            CNNBlock(64, 128, stride=2),\n            CNNBlock(128, 256, stride=2),\n            CNNBlock(256, 256, stride=2),\n            CNNBlock(256, 512, stride=2),\n            CNNBlock(512, 512, stride=1),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, padding_mode='reflect')\n\n        )\n        self.sigmoid = nn.Sigmoid()\n        self.flatten = nn.Flatten()\n    def forward(self, x, ):\n        x = self.initial(x)\n        return self.sigmoid(self.flatten(self.model(x)))","metadata":{"id":"X7wTcQVnoNjG","execution":{"iopub.status.busy":"2023-01-21T07:43:52.916423Z","iopub.execute_input":"2023-01-21T07:43:52.917282Z","iopub.status.idle":"2023-01-21T07:43:52.927790Z","shell.execute_reply.started":"2023-01-21T07:43:52.917247Z","shell.execute_reply":"2023-01-21T07:43:52.926794Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class DenDataset(Dataset):\n    def __init__(self, path, window):\n        self.window = window\n        self.path = path\n        self.x = torch.from_numpy(np.load(path + sorted(os.listdir(path))[0])['data_myo']).type(torch.FloatTensor)\n        for i in sorted(os.listdir(path)):\n            if i != sorted(os.listdir(path))[0]:\n                self.x = torch.cat([self.x, torch.from_numpy(np.load(path + i)['data_myo']).type(torch.FloatTensor)], dim=0)\n        x_add = self.x[0]\n        for i in range(self.window):\n            self.x = torch.cat([x_add[None], self.x], dim=0)\n    def __len__(self):\n        return (len(self.x) - 200) // 200\n\n    def __getitem__(self, idx):\n        x = self.x[idx:idx + self.window]\n        x = x.permute(1,0)\n        x=convertDF2MNE(x)\n        Wx, scales = cwt(x[0], 'morlet')\n        x=np.abs(Wx)\n        return resize(x, (8, 224, 224))","metadata":{"id":"IuuY9nNEbbcC","execution":{"iopub.status.busy":"2023-01-21T07:43:52.930236Z","iopub.execute_input":"2023-01-21T07:43:52.931442Z","iopub.status.idle":"2023-01-21T07:43:52.941130Z","shell.execute_reply.started":"2023-01-21T07:43:52.931409Z","shell.execute_reply":"2023-01-21T07:43:52.940054Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/working/data_train/'\n\n","metadata":{"id":"Mt5Sn5Tkdlgv","execution":{"iopub.status.busy":"2023-01-21T07:43:52.944089Z","iopub.execute_input":"2023-01-21T07:43:52.944558Z","iopub.status.idle":"2023-01-21T07:43:52.953594Z","shell.execute_reply.started":"2023-01-21T07:43:52.944520Z","shell.execute_reply":"2023-01-21T07:43:52.952564Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_ds = DenDataset(train_path, 200)\nloader = DataLoader(train_ds, batch_size=64, shuffle=True)\n","metadata":{"id":"op97fTMadaEL","execution":{"iopub.status.busy":"2023-01-21T07:43:52.957772Z","iopub.execute_input":"2023-01-21T07:43:52.958068Z","iopub.status.idle":"2023-01-21T07:43:54.008120Z","shell.execute_reply.started":"2023-01-21T07:43:52.958027Z","shell.execute_reply":"2023-01-21T07:43:54.007077Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n","metadata":{"id":"4_WJitZ0ibvI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"30c5caaa-259b-4997-cf28-f4bcb6a1ccfe","execution":{"iopub.status.busy":"2023-01-21T07:43:54.009566Z","iopub.execute_input":"2023-01-21T07:43:54.010284Z","iopub.status.idle":"2023-01-21T07:43:54.065813Z","shell.execute_reply.started":"2023-01-21T07:43:54.010236Z","shell.execute_reply":"2023-01-21T07:43:54.064538Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"discriminator = Descriminator().to(device)\ngenerator = Generator().to(device)","metadata":{"id":"jx6G9qWYh-h9","execution":{"iopub.status.busy":"2023-01-21T07:43:54.067450Z","iopub.execute_input":"2023-01-21T07:43:54.068319Z","iopub.status.idle":"2023-01-21T07:43:57.124169Z","shell.execute_reply.started":"2023-01-21T07:43:54.068279Z","shell.execute_reply":"2023-01-21T07:43:57.123132Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lr = 0.0002\n\nmodel = {\n    \"discriminator\": discriminator,\n    \"generator\": generator\n}\n\ncriterion = {\n    \"discriminator\": nn.BCELoss(),\n    \"generator\": nn.BCELoss()\n}","metadata":{"id":"G7S8Yh7Bbrgb","execution":{"iopub.status.busy":"2023-01-21T07:43:57.125952Z","iopub.execute_input":"2023-01-21T07:43:57.126401Z","iopub.status.idle":"2023-01-21T07:43:57.132624Z","shell.execute_reply.started":"2023-01-21T07:43:57.126362Z","shell.execute_reply":"2023-01-21T07:43:57.131436Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\ndef convertDF2MNE(sub):\n    info = mne.create_info([str(i) for i in range(len(sub))], ch_types=['eeg'] * len(sub), sfreq=200, verbose=False)\n    data=mne.io.RawArray(sub, info, verbose=False)\n    data.set_eeg_reference(verbose=False)\n    epochs=mne.make_fixed_length_epochs(data,duration=1,overlap=0, verbose=False)\n    return epochs._get_data(verbose=False)","metadata":{"id":"EdhutKHGd2Em","execution":{"iopub.status.busy":"2023-01-21T07:43:57.134368Z","iopub.execute_input":"2023-01-21T07:43:57.135243Z","iopub.status.idle":"2023-01-21T07:43:57.142748Z","shell.execute_reply.started":"2023-01-21T07:43:57.135206Z","shell.execute_reply":"2023-01-21T07:43:57.141894Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def noisy(image):\n    ch, row,col= image.shape\n    mean = 0\n    var = 0.1\n    sigma = var**0.5\n    gauss = np.random.normal(mean,sigma,(ch,row,col))\n    gauss = gauss.reshape(ch,row,col)\n    noisy = image + gauss\n    return noisy","metadata":{"id":"YfcNVNudcwfi","execution":{"iopub.status.busy":"2023-01-21T07:43:57.144350Z","iopub.execute_input":"2023-01-21T07:43:57.144789Z","iopub.status.idle":"2023-01-21T07:43:57.152569Z","shell.execute_reply.started":"2023-01-21T07:43:57.144754Z","shell.execute_reply":"2023-01-21T07:43:57.151476Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"batch_size=64","metadata":{"id":"GJw71-sjdTre","execution":{"iopub.status.busy":"2023-01-21T07:43:57.153869Z","iopub.execute_input":"2023-01-21T07:43:57.154282Z","iopub.status.idle":"2023-01-21T07:43:57.162586Z","shell.execute_reply.started":"2023-01-21T07:43:57.154242Z","shell.execute_reply":"2023-01-21T07:43:57.161728Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def fit(model, criterion, epochs, lr):\n    model[\"discriminator\"].train()\n    model[\"generator\"].train()\n  \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n  \n    # Create optimizers\n    optimizer = {\n      \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(), \n                                        lr=lr, betas=(0.5, 0.999)),\n      \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n                                    lr=lr, betas=(0.5, 0.999))\n  }\n  \n    for epoch in range(epochs):\n        loss_d_per_epoch = []\n        loss_g_per_epoch = []\n        real_score_per_epoch = []\n        fake_score_per_epoch = []\n        for real_images in tq.tqdm(loader):\n          # Train discriminator\n          # Clear discriminator gradients\n            real_images = real_images.to(device)\n            optimizer[\"discriminator\"].zero_grad()\n\n          # Pass real images through discriminator\n            real_preds = model[\"discriminator\"](real_images)\n            real_targets = torch.ones(real_images.size(0), 1, device=device)\n            real_loss = criterion[\"discriminator\"](real_preds, real_targets)\n            cur_real_score = torch.mean(real_preds).item()\n          \n          # Generate fake images\n            for i in range(len(real_images)):\n                real_images[i] = torch.from_numpy(noisy(real_images[i].cpu().detach().numpy()))\n            latent = real_images\n            fake_images = model[\"generator\"](latent)\n\n          # Pass fake images through discriminator\n            fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n            fake_preds = model[\"discriminator\"](fake_images)\n            fake_loss = criterion[\"discriminator\"](fake_preds, fake_targets)\n            cur_fake_score = torch.mean(fake_preds).item()\n\n            real_score_per_epoch.append(cur_real_score)\n            fake_score_per_epoch.append(cur_fake_score)\n\n          # Update discriminator weights\n            loss_d = real_loss + fake_loss\n            loss_d.backward()\n            optimizer[\"discriminator\"].step()\n            loss_d_per_epoch.append(loss_d.item())\n\n\n          # Train generator\n          # Clear generator gradients\n            optimizer[\"generator\"].zero_grad()\n          \n          # Generate fake images\n            for i in range(len(real_images)):\n                real_images[i] = torch.from_numpy(noisy(real_images[i].cpu().detach().numpy()))\n            latent = real_images\n            fake_images = model[\"generator\"](latent)\n          \n          # Try to fool the discriminator\n            preds = model[\"discriminator\"](fake_images)\n            targets = torch.ones(preds.shape[0], 1, device=device)\n            loss_g = criterion[\"generator\"](preds, targets)\n          \n          # Update generator weights\n            loss_g.backward()\n            optimizer[\"generator\"].step()\n            loss_g_per_epoch.append(loss_g.item())\n          \n      # Record losses & scores\n        losses_g.append(np.mean(loss_g_per_epoch))\n        losses_d.append(np.mean(loss_d_per_epoch))\n        real_scores.append(np.mean(real_score_per_epoch))\n        fake_scores.append(np.mean(fake_score_per_epoch))\n      \n      # Log losses & scores (last batch)\n        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n          epoch+1, epochs, \n          losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1]))\n  \n  \n    return losses_g, losses_d, real_scores, fake_scores","metadata":{"id":"UN65mWqXbz9P","execution":{"iopub.status.busy":"2023-01-21T07:43:57.164145Z","iopub.execute_input":"2023-01-21T07:43:57.164584Z","iopub.status.idle":"2023-01-21T07:43:57.182060Z","shell.execute_reply.started":"2023-01-21T07:43:57.164549Z","shell.execute_reply":"2023-01-21T07:43:57.180991Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = fit(model, criterion, 25, lr)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["25141cba48d643adb3dbad1880d5c702","c1807486034c4e9f9c4ed140ca33e4fc","ac27047a741a4aaba1e5e96596430452","e7dc218627c640679febfd74c219123e","c5186f6d47b44eaa873385e871ebbbf8","e0f2af7d9430454e8b1b2a36d75ff178","2916384bc2e44d278c13d0cfddd00b5a","9b1acd2e5c2f4038babc5464c5dabf86","509b9e58ac384292bc13503ef7a36515","e7042627484d4551ab282c6ca08e76ac","0605f6f762cd4aeca4131234fb2dd8bd"]},"id":"OkFfJqxNhsM8","outputId":"f346d83e-4f13-4b7d-9f66-df6f9b003f31","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses_g, losses_d, real_scores, fake_scores = history","metadata":{"id":"2ayFcNQFie2L"},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nplt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 6))\n\nplt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","metadata":{},"execution_count":null,"outputs":[]}]}